{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cefee81",
   "metadata": {},
   "source": [
    "#### See the link for details on v2 Tweet object\n",
    "https://blog.twitter.com/developer/en_us/topics/tips/2020/understanding-the-new-tweet-payload\n",
    "\n",
    "- Specify \"Entity for URLS and mentions\n",
    "- \"data\" in the response contains tweet details\n",
    "- \"include\" in the response contains \n",
    " - user details\n",
    " - location info\n",
    " - whether the tweet was quoted\n",
    "- \"public_metrics\" nested in tweet object contains retweets, likes, etc.\n",
    "- \"public_metrics\" nested in user object contains followers, followes, etc.\n",
    "- \"non_public_metrics\" nested in tweet object contains impressions, video view, etc.\n",
    "- \"context_annotations\" in nested in tweet provides contextual information to help you understand what the Tweet is about without needing to do custom entity recognition.\n",
    " - Each object within context_annotations contains a ‘domain’ object and an ‘entity’ object, and each of those have an id and name property. The domain indicates the high level category or topic under which the Tweet falls, and the entity indicates the person, place, or organization that is recognized from the Tweet text. More details on available annotations can be found on our [documentation page](https://developer.twitter.com/en/docs/labs).\n",
    " \n",
    "See here for details of tweet object: https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8af106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from twitter_authentication import bearer_token\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time, os, sys\n",
    "import csv\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6cba5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_to_df(response):\n",
    "    '''\n",
    "    Converts Media objects returned with tweets to a dataframe.\n",
    "    '''\n",
    "    media = []\n",
    "    for m in response.includes['media']:\n",
    "        media.append(\n",
    "            { \n",
    "              'media_key': m.media_key,\n",
    "              'media_type': m.type, \n",
    "              'alt_text': m.alt_text,\n",
    "              'duration_ms': m.duration_ms\n",
    "             })\n",
    "    df = pd.DataFrame(media)\n",
    "    df.set_index(\"media_key\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def users_to_df(response):\n",
    "    '''\n",
    "    Converts Users objects returned with tweets to a dataframe.\n",
    "    '''\n",
    "    users = []\n",
    "    # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "    for user in response.includes['users']:\n",
    "        users.append(\n",
    "            { \n",
    "            'userid': user.id,\n",
    "            'username': user.username, \n",
    "            'followers': user.public_metrics['followers_count'],\n",
    "            'tweets': user.public_metrics['tweet_count'],\n",
    "            'profile_desc': user.description,\n",
    "            'location': user.location,\n",
    "            'verified': user.verified,\n",
    "            'entities': user.entities\n",
    "             })\n",
    "    df = pd.DataFrame(users)\n",
    "    df.set_index(\"userid\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def tweet_to_row(tweet):\n",
    "    return {\n",
    "        'tweetid': tweet.id,\n",
    "        'author_id': tweet.author_id, \n",
    "        'text': tweet.text,\n",
    "        'created_at': tweet.created_at,\n",
    "        'geo': tweet.geo,\n",
    "        'retweets': tweet.public_metrics['retweet_count'],\n",
    "        'replies': tweet.public_metrics['reply_count'],\n",
    "        'likes': tweet.public_metrics['like_count'],\n",
    "        'quote_count': tweet.public_metrics['quote_count'],\n",
    "        'lang':tweet.lang,\n",
    "        'conversation_id': tweet.conversation_id,\n",
    "        'mentions': [] if 'mentions' not in tweet.entities else tweet.entities['mentions'],\n",
    "        'urls': [] if 'urls' not in tweet.entities else tweet.entities['urls'],\n",
    "        'hashtags': [] if 'hashtags' not in tweet.entities else tweet.entities['hashtags'],\n",
    "        'referenced_tweets': [] if 'referenced_tweets' not in tweet.entities else tweet.entities['referenced_tweets'],\n",
    "        'context_annotations': tweet.context_annotations,\n",
    "        'attachments': tweet.attachments,\n",
    "        'possibly_sensitive': tweet.possibly_sensitive,\n",
    "        'withheld' : tweet.withheld,\n",
    "        'reply_settings': tweet.reply_settings,\n",
    "        'source':tweet.source\n",
    "        }\n",
    "\n",
    "def included_tweets_to_df(response):\n",
    "    result = []\n",
    "    for tweet in response.includes['tweets']:\n",
    "        result.append(tweet_to_row(tweet))\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    df.set_index('tweetid', inplace=True)\n",
    "    return df\n",
    "\n",
    "def tweets_to_df(response):\n",
    "    result = []\n",
    "    for tweet in response.data:\n",
    "        result.append(tweet_to_row(tweet))\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    df.set_index('tweetid', inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e8155682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(query, outdir):\n",
    "    tweet_count = 0\n",
    "    try:\n",
    "        for response in tweepy.Paginator(\n",
    "                client.search_all_tweets, \n",
    "                query = query,\n",
    "                user_fields = ['username', 'public_metrics', 'description', \n",
    "                               'location', 'protected', 'verified',\n",
    "                                'entities', 'url'],\n",
    "                tweet_fields = ['id', 'text', 'author_id', \n",
    "                                'created_at', 'geo', 'public_metrics',\n",
    "                                'lang', 'conversation_id', 'entities',\n",
    "                                'referenced_tweets', 'context_annotations', \n",
    "                                'attachments', 'possibly_sensitive',\n",
    "                                'withheld', 'reply_settings', 'source'\n",
    "                                #'organic_metrics', #'promoted_metrics', #'non_public_metrics',\n",
    "                               ],\n",
    "                expansions = ['author_id', 'referenced_tweets.id', \n",
    "                              'referenced_tweets.id.author_id',\n",
    "                              'in_reply_to_user_id', 'attachments.media_keys',\n",
    "                              'entities.mentions.username'],\n",
    "                start_time = '2006-03-21T00:00:00Z',\n",
    "        #         end_time = '2021-01-21T00:00:00Z',\n",
    "                place_fields=['full_name', 'id'],\n",
    "                media_fields=['type', 'url', 'alt_text', \n",
    "                              'public_metrics', 'duration_ms'],\n",
    "                max_results=10):\n",
    "\n",
    "            tweet_count+=len(response.data)\n",
    "            print('query: {}, tweets: {}, total: {}'.format(\n",
    "                query, len(response.data), tweet_count))\n",
    "\n",
    "            user_df = users_to_df(response)\n",
    "            tweet_df = tweets_to_df(response)\n",
    "            media_df = media_to_df(response)\n",
    "            included_tweet_df = included_tweets_to_df(response)\n",
    "\n",
    "            user_df.to_csv(\"{}/users-search-{}-{}.csv\".format(\n",
    "                outdir, query, datetime.datetime.now()))\n",
    "            tweet_df.to_csv(\"{}/tweets-search-{}-{}.csv\".format(\n",
    "                outdir, query, datetime.datetime.now()))\n",
    "            included_tweet_df.to_csv(\"{}/inc-tweets-search-{}-{}.csv\".format(\n",
    "                outdir, query, datetime.datetime.now()))\n",
    "            media_df.to_csv(\"{}/media-search-{}-{}.csv\".format(\n",
    "                outdir, query, datetime.datetime.now()))\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Exception for query:{}\".format(query))\n",
    "            with file in open('exceptions.txt', 'a'):\n",
    "                print(query+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5caf2ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_tweets(query=\"#edtech\", outdir=\"tweets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3244280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
